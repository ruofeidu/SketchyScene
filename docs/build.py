# Author: Ruofei Du
# This script builds the website by parsing the markdown text files and json files in data/
# This script also includes common files such as header and footer, and embed them into the final HTML
# from xml.etree import ElementTree as ET
from scripts.types import *
import re, json
import markdown
import htmlmin
import time

NUM_PAPERS = 0
build_time = time.time()
re_markdown = re.compile("<!--\s*include\s*:\s*data\/(.+)\.txt\s*?-->")
re_html = re.compile("<!--\s*include\s*:\s*(.+)\.html\s*?-->")
html, md, data, people = {}, {}, {}, {}


def remove_comments(html):
    return re.sub("(<!--.*?-->)", "", html, flags=re.DOTALL)


def remove_blank_lines(html):
    return re.sub("\n\s*\n", "\n", html, flags=re.DOTALL)


def read_str(file_name):
    with open(file_name, 'r') as f:
        s = ''.join(f.readlines())
    return s


def read_html(file_name):
    s = read_str(file_name + '.html')
    while re_markdown.search(s):
        key = re_markdown.search(s).groups()[0]
        print("%s\t<=\t%s.txt" % (file_name, key))
        s = re.sub("<!--\s*include\s*:\s*data\/" + key + "\.txt\s*-->", md[key], s, flags=re.DOTALL)
    while re_html.search(s):
        key = re_html.search(s).groups()[0]
        print("%s\t<=\t%s.html" % (file_name, key))
        s = re.sub("<!--\s*include\s*:\s*" + key + "\.html\s*-->", html[key], s, flags=re.DOTALL)
    return s


def read_content(file_name):
    s = read_html(file_name + '.content')
    while re_markdown.search(s):
        key = re_markdown.search(s).groups()[0]
        print("%s\t<=\t%s.txt" % (file_name, key))
        s = re.sub("<!--\s*include\s*:\s*data\/" + key + "\.txt\s*-->", md[key], s, flags=re.DOTALL)
    while re_html.search(s):
        key = re_html.search(s).groups()[0]
        print("%s\t<=\t%s.html" % (file_name, key))
        s = re.sub("<!--\s*include\s*:\s*" + key + "\.html\s*-->", html[key], s, flags=re.DOTALL)

    s = remove_comments(s)
    s = remove_blank_lines(s)
    return s


def build(file_name):
    print("---")
    s = read_content(file_name)
    # Build to separate folders
    # out_file = "%s.html" % file_name if file_name == 'index' else "%s/index.html" % file_name
    # Build to the root
    out_file = "%s.html" % file_name
    with open(out_file, 'w') as f:
        f.write('<!-- Automatically generated by build.py from MarkDown files -->\n')
        f.write('<!-- Augmentarium | UMIACS | University of Maryland, College Park -->\n')
        f.write(htmlmin.minify(s, remove_empty_space=True))


def read_markdown(file_name):
    s = read_str('data/' + file_name + '.txt')
    s = markdown.markdown(s)
    return s


def read_data(file_name):
    return json.load(open('data/' + file_name + '.json'))


def write_bib(b):
    filename = 'bib/' + b['bib'] + '.bib'
    if 'http' in filename:
        return
    print(filename)
    TAB = "&nbsp&nbsp&nbsp&nbsp"

    with open(filename, 'w') as f:
        f.write('@%s{%s,<br/>\n' % (b['type'], b['bibname']))
        f.write(TAB + 'title = {{%s}},<br/>\n' % b['title'])
        author_list = b['author']
        if 'authorb' in b:
            author_list = b['authorb']
        if 'bibauthor' in b:
            author_list = b['bibauthor']
        f.write(TAB + 'author = {%s},<br/>\n' % author_list)
        f.write(TAB + '%s = {%s},<br/>\n' % ('journal' if b['type'] == 'article' else 'booktitle', b['booktitle']))
        f.write(TAB + 'year = {%s},<br/>\n' % b['year'])
        if b['month']:
            f.write(TAB + 'month = {%s},<br/>\n' % b['month'])
        if b['day']:
            f.write(TAB + 'day = {%s},<br/>\n' % b['day'])
        if b['type'] == 'article':
            f.write(TAB + 'volume = {%s},<br/>\n' % b['volume'])
            f.write(TAB + 'number = {%s},<br/>\n' % b['number'])
        if b['editor']:
            f.write(TAB + 'editor = {%s},<br/>\n' % b['editor'])
        if b['location']:
            f.write(TAB + 'location = {%s},<br/>\n' % b['location'])
        elif b['address']:
            f.write(TAB + 'location = {%s},<br/>\n' % b['address'])
        if b['publisher']:
            f.write(TAB + 'publisher = {%s},<br/>\n' % b['publisher'])
        if b['series']:
            f.write(TAB + 'series = {%s},<br/>\n' % b['series'])
        if b['keywords']:
            f.write(TAB + 'keywords = {%s},<br/>\n' % b['keywords'])
        if b['doi']:
            f.write(TAB + 'doi = {%s},<br/>\n' % b['doi'])
        f.write(TAB + 'pages = {%s}<br/>\n' % b['pages'])
        f.write('}<br/>\n')

    filename = 'bib/' + b['bib'] + '.apa'

    with open(filename, 'w') as f:
        f.write('%s.' % b['apauthor'])
        f.write(' (%s).<br/> ' % (b['year']))
        f.write('%s.' % b['title'])
        f.write(' <br/>In <i>%s</i>' % b['booktitle'])
        if b['type'] == 'article':
            f.write(', %s(%s)' % (b['volume'], b['number']))
        f.write(', %s.' % b['pages'].replace('--', '-').replace(' ', ''))
        if b['doi']:
            f.write('<br/> DOI:%s' % b['doi'])

    filename = 'bib/' + b['bib'] + '.abstract'
    if b['abstract']:
        with open(filename, 'w') as f:
            f.write('%s' % b['abstract'])
    print(filename)


def write_data_to_markdown(file_name):
    global NUM_PAPERS
    LINE_MEMBERS = '<li><span class="image"><a href="%s"><img src="photos/%s" alt="%s" />' \
                   '</a></span><h3><a href="%s">%s</a></h3><p>%s</p></li>\n'

    CATEGORY = '### %s\n'
    NEW_ROW = '<ul class="faces">\n'
    ROW_END = '</ul>\n'
    HIDDEN_CATEGORIES = ['Faculty', 'Affiliated Faculty', 'Collaborators']

    with open("data/%s.txt" % file_name, 'w') as f:
        f.write('[comment]: <> (This markdown file is generated from %s.json by build.py)\n' % file_name)
        if file_name == 'members':
            categories = []
            count = 0
            f.write(NEW_ROW)
            for m in data['members']:
                m['name'] = m['name'].strip()
                people[m['name']] = m
                if m['visible']:
                    if count and count % 3 == 0:
                        f.write(ROW_END)
                        f.write(NEW_ROW)
                    f.write(LINE_MEMBERS % (
                        m['url'], m['photo'], m['name'] + "'s photo", m['url'], m['name'], m['current']))
                    count += 1
            f.write(ROW_END)


html_files = ['header']
data_files = ['members']
md_files = ['members']
build_files = ['index', 'people']

# First, parse Json Data and write to Markdown files
for f in data_files:
    data[f] = read_data(f)
for f in data_files:
    write_data_to_markdown(f)

# Next, read and parse HTML and MARKDOWN file for including
for f in md_files:
    md[f] = read_markdown(f)
for f in html_files:
    html[f] = read_html(f)

# Finally, generate combined files
for f in build_files:
    build(f)

print("Done! %d papers rendered. Time used %.2fs" % (NUM_PAPERS, time.time() - build_time))
